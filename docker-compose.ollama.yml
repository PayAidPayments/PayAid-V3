services:
  ollama:
    image: ollama/ollama:latest
    container_name: payaid-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      # Use CPU only (no GPU)
      - OLLAMA_NUM_GPU=0
      # Limit parallel requests
      - OLLAMA_NUM_PARALLEL=1
    deploy:
      resources:
        limits:
          memory: 2.8G  # Leave some memory for system
          cpus: '1.5'  # Limit CPU usage
        reservations:
          memory: 1.5G
    restart: unless-stopped

volumes:
  ollama-data:
    driver: local
