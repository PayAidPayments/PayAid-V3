/**
 * Database backup configuration script
 * Generates backup configuration and scripts
 */

import { writeFileSync } from 'fs'
import { join } from 'path'

const backupConfig = {
  // PostgreSQL backup configuration
  postgresql: {
    // Full backup schedule
    full: {
      schedule: '0 2 * * 0', // Every Sunday at 2 AM
      retention: 4, // Keep 4 weeks
      compression: true,
    },
    // Incremental backup schedule
    incremental: {
      schedule: '0 2 * * *', // Daily at 2 AM
      retention: 7, // Keep 7 days
      compression: true,
    },
    // Backup destination
    destination: {
      local: './backups',
      s3: {
        enabled: process.env.AWS_S3_BACKUP_BUCKET ? true : false,
        bucket: process.env.AWS_S3_BACKUP_BUCKET || '',
        region: process.env.AWS_REGION || 'us-east-1',
        path: 'database-backups',
      },
    },
  },

  // Backup commands
  commands: {
    full: `pg_dump $DATABASE_URL > backups/full-$(date +%Y%m%d-%H%M%S).sql`,
    incremental: `pg_dump $DATABASE_URL --schema-only > backups/incremental-$(date +%Y%m%d-%H%M%S).sql`,
    restore: `psql $DATABASE_URL < backups/[BACKUP_FILE].sql`,
  },
}

// Generate backup script
// Build script line by line to avoid template literal issues
const backupScriptLines = [
  '#!/bin/bash',
  '# Database Backup Script',
  '# Generated by setup-backups.ts',
  '',
  'set -e',
  '',
  'BACKUP_DIR="./backups"',
  'TIMESTAMP=$(date +%Y%m%d-%H%M%S)',
  'BACKUP_FILE="full-${TIMESTAMP}.sql"',
  '',
  '# Create backup directory if it doesn\'t exist',
  'mkdir -p $BACKUP_DIR',
  '',
  '# Full backup',
  'echo "Starting full backup..."',
  'pg_dump $DATABASE_URL | gzip > "$BACKUP_DIR/$BACKUP_FILE.gz"',
  '',
  '# Upload to S3 if configured',
  'if [ ! -z "$AWS_S3_BACKUP_BUCKET" ]; then',
  '  echo "Uploading to S3..."',
  '  aws s3 cp "$BACKUP_DIR/$BACKUP_FILE.gz" "s3://$AWS_S3_BACKUP_BUCKET/database-backups/$BACKUP_FILE.gz"',
  'fi',
  '',
  '# Cleanup old backups (keep last 4 weeks)',
  'find $BACKUP_DIR -name "full-*.sql.gz" -mtime +28 -delete',
  '',
  'echo "Backup completed: $BACKUP_FILE.gz"',
]
const backupScript = backupScriptLines.join('\n')

// Write configuration and script
const configDir = join(process.cwd(), 'config')
const scriptsDir = join(process.cwd(), 'scripts', 'infrastructure')

try {
  writeFileSync(
    join(configDir, 'backups.json'),
    JSON.stringify(backupConfig, null, 2)
  )
  console.log('âœ… Backup configuration created: config/backups.json')

  writeFileSync(join(scriptsDir, 'backup-database.sh'), backupScript)
  console.log('âœ… Backup script created: scripts/infrastructure/backup-database.sh')

  // Make script executable (Unix/Linux/Mac)
  if (process.platform !== 'win32') {
    const { execSync } = require('child_process')
    execSync(`chmod +x ${join(scriptsDir, 'backup-database.sh')}`)
    console.log('âœ… Backup script made executable')
  }

  console.log('\nðŸ“‹ Next Steps:')
  console.log('1. Set environment variables:')
  console.log('   - DATABASE_URL (required)')
  console.log('   - AWS_S3_BACKUP_BUCKET (optional, for S3 backups)')
  console.log('   - AWS_REGION (optional, for S3 backups)')
  console.log('2. Install AWS CLI (if using S3):')
  console.log('   - https://aws.amazon.com/cli/')
  console.log('3. Setup cron job (Linux/Mac) or Task Scheduler (Windows):')
  console.log('   - See docs/BACKUP_SETUP.md for details')
  console.log('4. Test backup:')
  console.log('   - Run: ./scripts/infrastructure/backup-database.sh')
} catch (error) {
  console.error('Error creating backup configuration:', error)
  process.exit(1)
}
